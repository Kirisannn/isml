{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.loadtxt(\"train.csv\", delimiter=\",\")\n",
    "testing_data = np.loadtxt(\"test.csv\", delimiter=\",\")\n",
    "\n",
    "# Split training data\n",
    "X = training_data[:, 1:]\n",
    "y = training_data[:, 0]\n",
    "y[y == 0] = -1 # Convert labels from {0,1} to {-1,1}\n",
    "X_train = X[:4000] # Use the first 4000 samples as training data\n",
    "y_train = y[:4000]\n",
    "X_val = X[4000:] # Remaining samples as validation data\n",
    "y_val = y[4000:]\n",
    "\n",
    "# Split testing data\n",
    "X_test = testing_data[:, 1:]\n",
    "y_test = testing_data[:, 0]\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the trained SVM model parameters using primal form\n",
    "def svm_train_primal(data_train, label_train, regularisation_para_C):\n",
    "    num_samples, num_features = data_train.shape\n",
    "\n",
    "    w = cp.Variable(num_features, value=np.zeros(num_features)) # Weight vector\n",
    "    b = cp.Variable(value=0.0) # Bias term\n",
    "    xi = cp.Variable(num_samples) # Slack variables\n",
    "\n",
    "    # Define objective function\n",
    "    objective = cp.Minimize(0.5 * cp.norm(w,2)**2 + regularisation_para_C * cp.sum(xi) / num_samples)\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [label_train[i] * (data_train[i] @ w + b) >= 1 - xi[i] for i in range(num_samples)]\n",
    "    constraints += [xi >= 0]\n",
    "    \n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    # Return SVM model parameters\n",
    "    svm_primal_model = {\"w\": w.value, \"b\": b.value, \"xi\": xi.value}\n",
    "    return svm_primal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on testing data and calculate accuracy\n",
    "def svm_predict_primal(data_test, label_test, svm_primal_model):\n",
    "    w = svm_primal_model[\"w\"]\n",
    "    b = svm_primal_model[\"b\"]\n",
    "\n",
    "    pred = np.sign(data_test @ w + b)\n",
    "    accuracy = np.mean(pred == label_test)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias (b) of SVM model is: 1.7798137266344365\n",
      "Sum of all dimensions of weight vector (w) is: -0.14521544474819548\n",
      "Resulting accuracy on validation data is: 0.9695555555555555\n",
      "Resulting accuracy on test data is: 0.968\n"
     ]
    }
   ],
   "source": [
    "# Train primal model with C=100 and then test\n",
    "svm_primal_model = svm_train_primal(X_train, y_train, 100)\n",
    "val_accuracy = svm_predict_primal(X_val, y_val, svm_primal_model)\n",
    "test_accuracy = svm_predict_primal(X_test, y_test, svm_primal_model)\n",
    "\n",
    "print(f\"Bias (b) of SVM model is: {svm_primal_model['b']}\")\n",
    "print(f\"Sum of all dimensions of weight vector (w) is: {np.sum(svm_primal_model['w'])}\")\n",
    "print(f\"Resulting accuracy on validation data is: {val_accuracy}\")\n",
    "print(f\"Resulting accuracy on test data is: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the trained SVM model parameters using dual form\n",
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    num_samples, num_features = data_train.shape\n",
    "\n",
    "    alpha = cp.Variable(num_samples) # Optimization variable\n",
    "    # kernel = data_train @ data_train.T\n",
    "\n",
    "    # Define objective function\n",
    "    objective = cp.Maximize(cp.sum(alpha) - 0.5 * cp.sum_squares(cp.multiply(alpha, label_train) @ data_train))\n",
    "    \n",
    "    # Define constraints\n",
    "    constraints = [\n",
    "        alpha >= 0,\n",
    "        alpha <= regularisation_para_C / num_samples,\n",
    "        cp.sum(cp.multiply(alpha, label_train)) == 0\n",
    "    ]\n",
    "    \n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.CVXOPT)\n",
    "\n",
    "    # Return SVM model parameter\n",
    "    svm_dual_model = {\"alpha\": alpha.value}\n",
    "    return svm_dual_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all dimensions of optimal alpha is: 7.281635912065749\n"
     ]
    }
   ],
   "source": [
    "# Train dual model with C=100\n",
    "svm_dual_model = svm_train_dual(X_train, y_train, 100)\n",
    "\n",
    "print(f\"Sum of all dimensions of optimal alpha is: {np.sum(svm_dual_model['alpha'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all dimensions of weight vector for primal problem from dual solution is: -0.145205601444225\n",
      "Solution of bias term from primal problem from dual solution is: 1.7389405965797873\n"
     ]
    }
   ],
   "source": [
    "# To obtain primal problem solution from dual problem\n",
    "alpha = svm_dual_model['alpha']\n",
    "num_samples, num_features = X_train.shape\n",
    "\n",
    "# Calculate weight vector\n",
    "w_star = np.sum(alpha[:, None] * y_train[:, None] * X_train, axis=0)\n",
    "\n",
    "# Calculate bias term by identifying support vectors where their alpha > 0\n",
    "support_vectors = np.where(alpha > 1e-5)[0]\n",
    "bias_support_vectors = y_train[support_vectors] - np.dot(X_train[support_vectors], w_star)\n",
    "b_star = np.mean(bias_support_vectors) # Average bias values\n",
    "\n",
    "print(f\"Sum of all dimensions of weight vector for primal problem from dual solution is: {np.sum(w_star)}\")\n",
    "print(f\"Solution of bias term from primal problem from dual solution is: {b_star}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors found from primal solutions is: 392\n"
     ]
    }
   ],
   "source": [
    "# To find support vectors from primal solutions\n",
    "constraint = X_train@svm_primal_model[\"w\"] + svm_primal_model[\"b\"] # Constraint of primal problem\n",
    "\n",
    "# Identify support vectors that fit the constraint\n",
    "support_vectors = (np.multiply(y_train, constraint) - 1 + svm_primal_model[\"xi\"]) <= 1e-4\n",
    "primal_support_vectors = X_train[support_vectors]\n",
    "\n",
    "print(f\"Number of support vectors found from primal solutions is: {len(primal_support_vectors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors found from dual solution is: 392\n"
     ]
    }
   ],
   "source": [
    "# To find support vectors from dual solution\n",
    "support_vectors = np.where(alpha > 1e-5)[0] # Identify support vectors that fit the dual constraint\n",
    "dual_support_vectors = X_train[support_vectors]\n",
    "\n",
    "print(f\"Number of support vectors found from dual solution is: {len(dual_support_vectors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find optimal regularisation parameter C using grid search\n",
    "def find_optimal_C(data_train, label_train, data_val, label_val, C_values):\n",
    "    optimal_C = None\n",
    "    optimal_accuracy = 0\n",
    "\n",
    "    # Train and test svm model with different values of C using primal solution\n",
    "    for regularisation_para_C in C_values:\n",
    "        svm_primal_model = svm_train_primal(data_train, label_train, regularisation_para_C)\n",
    "        val_accuracy = svm_predict_primal(data_val, label_val, svm_primal_model)\n",
    "\n",
    "        # If current validation accuracy is higher than current optimal accuracy, update\n",
    "        if val_accuracy > optimal_accuracy:\n",
    "            optimal_C = regularisation_para_C\n",
    "            optimal_accuracy = val_accuracy\n",
    "    \n",
    "    return optimal_C, optimal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal regularisation parameter C is: 4 with validation accuracy of 0.9748888888888889\n",
      "Test accuracy of primal model using optimal C is: 0.9746666666666667\n"
     ]
    }
   ],
   "source": [
    "# To find optimal C\n",
    "C_values = [2**-10, 2**-8, 2**-6, 2**-4, 2**-2, 2**0, 2**2, 2**4, 2**8, 2**10] # 2**-10, 2**100, optimal - 0.0039...\n",
    "optimal_C, optimal_accuracy = find_optimal_C(X_train, y_train, X_val, y_val, C_values)\n",
    "\n",
    "print(f\"Optimal regularisation parameter C is: {optimal_C} with validation accuracy of {optimal_accuracy}\")\n",
    "\n",
    "# To report test accuracy using optimal C\n",
    "svm_primal_model = svm_train_primal(X_train, y_train, optimal_C)\n",
    "test_accuracy = svm_predict_primal(X_test, y_test, svm_primal_model)\n",
    "\n",
    "print(f\"Test accuracy of primal model using optimal C is: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM model with penalty 'l1' and loss 'squared_hinge' with optimal C '4':\n",
      "Validation accuracy: 0.964 and test accuracy: 0.9713333333333334\n"
     ]
    }
   ],
   "source": [
    "# To perform classification with linear SVM using Scikit-Learn SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Testing with penalty \"l1\" and loss \"squared_hinge\"\n",
    "model = LinearSVC(penalty='l1', loss='squared_hinge', C=optimal_C, max_iter=10000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "val_predict = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_predict)\n",
    "\n",
    "# Predict on test set\n",
    "test_predict = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predict)\n",
    "\n",
    "print(f\"LinearSVM model with penalty 'l1' and loss 'squared_hinge' with optimal C '{optimal_C}':\")\n",
    "print(f\"Validation accuracy: {val_accuracy} and test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM model with penalty 'l2' and loss 'squared_hinge' with optimal C '4':\n",
      "Validation accuracy: 0.964 and test accuracy: 0.9713333333333334\n"
     ]
    }
   ],
   "source": [
    "# Testing with penalty \"l2\" and loss \"squared_hinge\"\n",
    "model = LinearSVC(penalty='l2', loss='squared_hinge', C=optimal_C, max_iter=10000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "val_predict = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_predict)\n",
    "\n",
    "# Predict on test set\n",
    "test_predict = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predict)\n",
    "\n",
    "print(f\"LinearSVM model with penalty 'l2' and loss 'squared_hinge' with optimal C '{optimal_C}':\")\n",
    "print(f\"Validation accuracy: {val_accuracy} and test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hence, final test accuracy of classification with LinearSVM model using Scikit-learn is 0.9713 or 97.13%*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
